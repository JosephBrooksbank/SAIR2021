#### TO INSTALL
* move this entire folder (du_brooksbank_joseph_project_2) to the src root of your catkin workspace (something like ~/catkin_ws/src)
* run catkin_make from the root of your catkin workspace ( ex ~/catkin_ws/ )
* source from .../catkin_ws/devel/setup.(bash|zsh) depending on what shell you are using


#### TO RUN

## Ensure that roscore, Gazebo and the slam mapping are both running:
roscore
roslaunch turtlebot3_gazebo turtlebot3_stage_4.launch
roslaunch turtlebot3_slam turtlebot3_slam.launch slam_methods:=gmapping

## Ensure that you are sourced properly as described in step 3 of #### TO INSTALL

## Run the launch script from this package
roslaunch du_brooksbank_joseph_project_2 turtlebot3_navigation.launch

## if you wish to view the current coordinate data of the robot, run in a new terminal:
rostopic echo /turtle_position

## To view information in RViz:
# Click "Add"
# for raw frontiers, add a 'map' which subscribes to the topic 'frontiers_map'
# for clustered frontiers/observation points, add a 'markers array' and subscribe to topic 'frontier_markers'.
## (Part 3) Using config file
# The config file found in ./rviz_configs can be used instead of the above steps, simply File -> Open it in RViz.


## PART 1 (DEPRECATED)
# the robot should begin moving toward its first goal of  (-1.0, 1.0, 0.0), and then to (-1.0, -1.0, 0), where it will stop.

## PART 2 (DEPRECATED)
# The robot will not move, however clusters of frontier data will appear, along with red circles to mark the centers of each frontier.

## Sample video:
https://youtu.be/af0odgvD_jo

### PART 2 Notes:
# As you mentioned in Project 1, my laser output seems to be more sparse than yours is in the examples. I am not sure
# Why this is, but it has only minor implications for frontier generation, so I think it works.
# For clustering, I am using the sklearn AgglomerativeClustering algorithm. It works okay, but definitely some weird things sometimes.


### PART 3 (CURRENT)

## Notable changes:
# Rewrote project using OOP. Much more readable and debuggable now. Enforces typing where possible, but python 2 doesn't
# have great support for that. (Maybe its time to move to ROS Noetic?)

# There is now an RViz config file located in ./rviz_configs. It can be loaded in RViz in the "File -> Open" option.


# The robot should compute frontiers and centroids as in part 2. Furthermore, it will select the closest centroid and
# mark it in a slightly larger green circle, and begin navigating towards that circle.
# When the robot gets close enough to the goal or 15 seconds have passed, a new goal will be chosen.
# Once there are no more frontiers available, the process will exit.

### Part 3 Notes
# This was my favorite part of the project so far. I finally got around to stepping back and using a class based structure
# which I should have done from the start, but long enough working at one time and I eventually go into the 'whatever runs, works' mode.
#
# ¯\_(ツ)_/¯
#
# It was cool to see the exploration actually working, and I am very happy with my tuning for tolerance and frontier picking.
# I haven't had to unstick it a single time, starting it from multiple different positions.



